{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import cv2\n",
    "from PIL import Image\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"microsoft/cats_vs_dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds['train'][0]['image'])\n",
    "print(ds['train'][0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "target_size = (128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_square(image):\n",
    "    width, height = image.size\n",
    "\n",
    "    # If the image is already square, return the original image\n",
    "    if width == height:\n",
    "        return image\n",
    "\n",
    "    # Determine the size of the new square image (it should be the max of width and height)\n",
    "    new_size = max(width, height)\n",
    "\n",
    "    # Create a new black image with a square size\n",
    "    new_image = Image.new(\"RGB\", (new_size, new_size), color=(0, 0, 0))  # Black background\n",
    "\n",
    "    # Calculate the position to paste the original image (centered)\n",
    "    paste_position = ((new_size - width) // 2, (new_size - height) // 2)\n",
    "\n",
    "    # Paste the original image onto the new black square\n",
    "    new_image.paste(image, paste_position)\n",
    "\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('iterating through the dataset')\n",
    "print('processing...')\n",
    "for row in ds['train']:\n",
    "    image = row['image']\n",
    "    \n",
    "    new_image = make_square(image)\n",
    "    \n",
    "    image_resized = new_image.resize(target_size)\n",
    "    image_np = np.array(image_resized)\n",
    "    all_images.append(image_np)\n",
    "    \n",
    "    label = row['labels']\n",
    "    all_labels.append(label)\n",
    "    \n",
    "print('Done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of everything\n",
    "count = 0\n",
    "for image in all_images:\n",
    "    if len(image.shape) != 3 or (len(image.shape) == 3 and image.shape[2] != 3):\n",
    "        print(f'shape: {image.shape}')\n",
    "        count += 1\n",
    "        \n",
    "print(f'count: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Issue**\n",
    "\n",
    "We have 5 pictures that don't have 3 channels but just one. We have to eliminate those in order to conver all_images from a list to a numpy array\n",
    "\n",
    "I've tried to eliminated the elements that have the shape == 2 but with the .remove() method it didn't work. So we have to repopulate another list\n",
    "\n",
    "after a couple of trial there I founded that there are some images where the last axis has 4 channels instead of 3 (I don't know why, i guess it is some alpha value), so I'm gonna get rid of those images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = []\n",
    "count_list = []\n",
    "count = 0\n",
    "\n",
    "for image in all_images:\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "        temp_list.append(image)\n",
    "    else:\n",
    "        count_list.append(count)\n",
    "    count += 1\n",
    "    \n",
    "for count in reversed(count_list):\n",
    "    all_labels.pop(count)\n",
    "    \n",
    "all_images = temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = np.array(all_images)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "print(f'shape images np array: {all_images.shape}')\n",
    "print(f'shape labels np array: {all_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the two arrays into files\n",
    "import os\n",
    "\n",
    "folder_name = '../npy_file'\n",
    "\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "np.save('../npy_file/images.npy', all_images)\n",
    "np.save('../npy_file/labels.npy', all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.fromarray(all_images[0])\n",
    "#image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = all_images/255.0\n",
    "\n",
    "input_shape = (128, 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_images, all_labels, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(input_shape=input_shape, filters=16, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(filters=16, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 32\n",
    "epochs = 10\n",
    "\n",
    "steps_per_epoch = int(np.ceil(len(X_train)/batch))\n",
    "validation_steps = int(np.ceil(len(X_test)/batch))\n",
    "\n",
    "folder_name = '../ai_models'\n",
    "\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    " \n",
    "best_model_file = os.path.join(folder_name, 'cat_dog_squared_10.keras')\n",
    "\n",
    "best_model = ModelCheckpoint(best_model_file, monitor = 'val_accuracy', verbose = 1, save_best_only = True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size = batch,\n",
    "                    epochs = epochs,\n",
    "                    verbose = 1,\n",
    "                    validation_data = (X_test, y_test),\n",
    "                    validation_steps = validation_steps,\n",
    "                    steps_per_epoch = steps_per_epoch,\n",
    "                    shuffle = True,\n",
    "                    callbacks = [best_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
